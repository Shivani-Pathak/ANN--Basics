{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5oAc93hEQYLFfuGLckaoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivani-Pathak/ANN--Basics/blob/main/Basic_NN_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2UEN8yjQTH7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train).astype('float32')\n",
        "X_test = scaler.transform(X_test).astype('float32')\n",
        "\n",
        "# get in pytorch tensor form\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1) # (n, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1) # (n, 1)) # (n, 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "ITQbkPLbR2Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloader and tensordataset\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle= True)"
      ],
      "metadata": {
        "id": "2fKiMv1sTKl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# neural network\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8,64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32,1)\n",
        ")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLMb0u87T-o_",
        "outputId": "8e2146b2-b242-4a39-cde0-44f650f5d424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=8, out_features=64, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and it's optimisation\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "optimizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hqEHbigUu-_",
        "outputId": "4063b16b-1482-4017-f0b1-60c2990c2a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Adam (\n",
              "Parameter Group 0\n",
              "    amsgrad: False\n",
              "    betas: (0.9, 0.999)\n",
              "    capturable: False\n",
              "    differentiable: False\n",
              "    eps: 1e-08\n",
              "    foreach: None\n",
              "    fused: None\n",
              "    lr: 0.001\n",
              "    maximize: False\n",
              "    weight_decay: 0\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "epoch = 20\n",
        "for epoch in range(epoch):\n",
        "  total_loss = 0\n",
        "  for batch_X, batch_y in train_loader:\n",
        "    optimizer.zero_grad\n",
        "    prediction = model(batch_X)\n",
        "    loss = criterion(prediction, batch_y)\n",
        "    loss.backward()\n",
        "    optimizer.step() #  performs a single optimization step, updating the model parameters based on the computed gradients\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  avg_loss = total_loss / len(train_loader)\n",
        "  print(f\"Epoch {epoch}, Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fICVmmO5VQNe",
        "outputId": "e84f2c03-82c1-46cd-e2df-f752ca2d6fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Average Loss: 2.3140\n",
            "Epoch 1, Average Loss: 1.4736\n",
            "Epoch 2, Average Loss: 1.2121\n",
            "Epoch 3, Average Loss: 1.4509\n",
            "Epoch 4, Average Loss: 1.8115\n",
            "Epoch 5, Average Loss: 1.6511\n",
            "Epoch 6, Average Loss: 1.3835\n",
            "Epoch 7, Average Loss: 1.6783\n",
            "Epoch 8, Average Loss: 1.7249\n",
            "Epoch 9, Average Loss: 1.3804\n",
            "Epoch 10, Average Loss: 1.5813\n",
            "Epoch 11, Average Loss: 1.7203\n",
            "Epoch 12, Average Loss: 1.3922\n",
            "Epoch 13, Average Loss: 1.5535\n",
            "Epoch 14, Average Loss: 1.6877\n",
            "Epoch 15, Average Loss: 1.3839\n",
            "Epoch 16, Average Loss: 1.5612\n",
            "Epoch 17, Average Loss: 1.6312\n",
            "Epoch 18, Average Loss: 1.3681\n",
            "Epoch 19, Average Loss: 1.6062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  prediction = model(X_test_tensor)\n",
        "  mse = criterion(prediction, y_test_tensor)\n",
        "  print(f\"MSE on test set: {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTGSe6xtWzdc",
        "outputId": "9e2bb286-ce29-4b28-b4a9-25098c78edb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE on test set: 1.6488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DO the prediction y= wx + b\n",
        "with torch.no_grad():\n",
        "  sample= torch.tensor(X_test[0]).unsqueeze(0) #shape will be (1,8)\n",
        "  prediction = model(sample)\n",
        "  print(f\"Predicted price:{prediction}, Actual price: {y_test[0]:.2f}\")\n",
        "  print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT0kgiRiXXD0",
        "outputId": "8e538a0f-400a-4086-d04d-c8e192758154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price:tensor([[1.4733]]), Actual price: 0.48\n",
            "tensor([[1.4733]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data.astype('float32'), data.target.astype('float32')\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train).astype('float32')\n",
        "X_test = scaler.transform(X_test).astype('float32')\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "y_train_tensor = torch.tensor(y_train).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test)\n",
        "y_test_tensor = torch.tensor(y_test).unsqueeze(1)\n",
        "\n",
        "# DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(8, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ")\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        preds = model(batch_X)\n",
        "        loss = criterion(preds, batch_y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test_tensor)\n",
        "    test_loss = criterion(preds, y_test_tensor)\n",
        "    print(f\"\\nTest MSE: {test_loss.item():.4f}\")\n",
        "\n",
        "    sample = torch.tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "  sample= torch.tensor(X_test[0]).unsqueeze(0) #shape will be (1,8)\n",
        "  prediction = model(sample)\n",
        "  print(f\"Predicted price:{prediction}, Actual price: {y_test[0]:.2f}\")\n",
        "  print(prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkQ_At9RYcDg",
        "outputId": "5492db68-2dc9-492f-8013-bc58d02e3096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9884\n",
            "Epoch 2, Loss: 0.4353\n",
            "Epoch 3, Loss: 0.3944\n",
            "Epoch 4, Loss: 0.3730\n",
            "Epoch 5, Loss: 0.3639\n",
            "Epoch 6, Loss: 0.3453\n",
            "Epoch 7, Loss: 0.3326\n",
            "Epoch 8, Loss: 0.3261\n",
            "Epoch 9, Loss: 0.3149\n",
            "Epoch 10, Loss: 0.3094\n",
            "Epoch 11, Loss: 0.3085\n",
            "Epoch 12, Loss: 0.3023\n",
            "Epoch 13, Loss: 0.2992\n",
            "Epoch 14, Loss: 0.2974\n",
            "Epoch 15, Loss: 0.2933\n",
            "Epoch 16, Loss: 0.2925\n",
            "Epoch 17, Loss: 0.2894\n",
            "Epoch 18, Loss: 0.2893\n",
            "Epoch 19, Loss: 0.2885\n",
            "Epoch 20, Loss: 0.2844\n",
            "\n",
            "Test MSE: 0.2932\n",
            "Predicted price:tensor([[0.5482]]), Actual price: 0.48\n",
            "tensor([[0.5482]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u-0ASdpMavJv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}